{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-08T14:02:03.001939Z","iopub.status.busy":"2023-09-08T14:02:03.000882Z","iopub.status.idle":"2023-09-08T14:02:20.695632Z","shell.execute_reply":"2023-09-08T14:02:20.694503Z","shell.execute_reply.started":"2023-09-08T14:02:03.001895Z"},"trusted":true},"outputs":[],"source":["# !pip install mediapipe "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T14:02:20.698311Z","iopub.status.busy":"2023-09-08T14:02:20.697943Z","iopub.status.idle":"2023-09-08T14:02:21.995197Z","shell.execute_reply":"2023-09-08T14:02:21.993872Z","shell.execute_reply.started":"2023-09-08T14:02:20.698276Z"},"trusted":true},"outputs":[],"source":["# !wget https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T15:26:17.041919Z","iopub.status.busy":"2023-09-08T15:26:17.041460Z","iopub.status.idle":"2023-09-08T15:26:17.046697Z","shell.execute_reply":"2023-09-08T15:26:17.045905Z","shell.execute_reply.started":"2023-09-08T15:26:17.041884Z"},"trusted":true},"outputs":[],"source":["model_path = 'face_landmarker.task'"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T15:26:17.051953Z","iopub.status.busy":"2023-09-08T15:26:17.051473Z","iopub.status.idle":"2023-09-08T15:26:17.062581Z","shell.execute_reply":"2023-09-08T15:26:17.061371Z","shell.execute_reply.started":"2023-09-08T15:26:17.051916Z"},"trusted":true},"outputs":[],"source":["import mediapipe as mp\n","from mediapipe import solutions\n","from mediapipe.framework.formats import landmark_pb2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.protobuf import timestamp_pb2\n","from statistics import mean"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T15:39:19.164231Z","iopub.status.busy":"2023-09-08T15:39:19.163710Z","iopub.status.idle":"2023-09-08T15:39:19.170350Z","shell.execute_reply":"2023-09-08T15:39:19.169107Z","shell.execute_reply.started":"2023-09-08T15:39:19.164194Z"},"trusted":true},"outputs":[],"source":["# video_path = '/kaggle/input/trialvideo/sample.mp4'"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T15:26:17.080882Z","iopub.status.busy":"2023-09-08T15:26:17.080493Z","iopub.status.idle":"2023-09-08T15:26:17.094885Z","shell.execute_reply":"2023-09-08T15:26:17.093692Z","shell.execute_reply.started":"2023-09-08T15:26:17.080825Z"},"trusted":true},"outputs":[],"source":["def draw_landmarks_on_image(rgb_image, detection_result):\n","  # face_landmarks_list = detection_result.face_landmarks\n","  annotated_image = np.copy(rgb_image)\n","\n","  # Loop through the detected faces to visualize.\n","  for idx in range(len(detection_result)):\n","    face_landmarks = detection_result[idx]\n","\n","    # Draw the face landmarks.\n","    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n","    face_landmarks_proto.landmark.extend([\n","      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n","    ])\n","\n","    # solutions.drawing_utils.draw_landmarks(\n","    #     image=annotated_image,\n","    #     landmark_list=face_landmarks_proto,\n","    #     connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n","    #     landmark_drawing_spec=None,\n","    #     connection_drawing_spec=mp.solutions.drawing_styles\n","    #     .get_default_face_mesh_tesselation_style())\n","    solutions.drawing_utils.draw_landmarks(\n","        image=annotated_image,\n","        landmark_list=face_landmarks_proto,\n","        # connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n","        landmark_drawing_spec=solutions.drawing_utils.DrawingSpec(color=(0, 0, 0, 0), thickness=0, circle_radius=2),\n","        # connection_drawing_spec=mp.solutions.drawing_styles\n","        # .get_default_face_mesh_contours_style()\n","        )\n","    # solutions.drawing_utils.draw_landmarks(\n","    #     image=annotated_image,\n","    #     landmark_list=face_landmarks_proto,\n","    #     connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n","    #       landmark_drawing_spec=None,\n","    #       connection_drawing_spec=mp.solutions.drawing_styles\n","    #       .get_default_face_mesh_iris_connections_style())\n","\n","  return annotated_image"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from mediapipe.tasks.python.components.containers import NormalizedLandmark"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# lm = NormalizedLandmark(0.0, 0.0, 0.0, 0.0, 0.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T15:39:23.184394Z","iopub.status.busy":"2023-09-08T15:39:23.183955Z","iopub.status.idle":"2023-09-08T15:39:37.807414Z","shell.execute_reply":"2023-09-08T15:39:37.806076Z","shell.execute_reply.started":"2023-09-08T15:39:23.184358Z"},"trusted":true},"outputs":[],"source":["BaseOptions = mp.tasks.BaseOptions\n","FaceLandmarker = mp.tasks.vision.FaceLandmarker\n","FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n","FaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult\n","VisionRunningMode = mp.tasks.vision.RunningMode\n","\n","# Create a face landmarker instance with the live stream mode:\n","def print_result(result: FaceLandmarkerResult, output_image: mp.Image, timestamp_ms: int):\n","    print('face landmarker result: {}'.format(result))\n","\n","options = FaceLandmarkerOptions(\n","    base_options=BaseOptions(model_asset_path=model_path),\n","    running_mode=VisionRunningMode.VIDEO)\n","\n","landmarker = FaceLandmarker.create_from_options(options)\n","cap = cv2.VideoCapture(0)\n","# cap = cv2.VideoCapture('IMG-4778.MOV')\n","cap. set(cv2.CAP_PROP_FPS, 30)\n","\n","# Path to the output video file\n","output_path = 'output_video.mp4'\n","\n","# Configure output video properties\n","codec = cv2.VideoWriter_fourcc(*'mp4v')\n","frame_width = 0  # Set to 0 to use the same width as the input video\n","frame_height = 0  # Set to 0 to use the same height as the input video\n","fps = 30  # Set the desired output frame rate\n","\n","# Check if video was successfully opened\n","if not cap.isOpened():\n","    print(\"Failed to open the video file.\")\n","    exit()\n","\n","# Get input video properties\n","if frame_width == 0:\n","    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","if frame_height == 0:\n","    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Create video writer object\n","# out = cv2.VideoWriter(output_path, codec, fps, (frame_width, frame_height))\n","\n","# Path to the output video file\n","output_path = 'output_video.mp4'\n","\n","# Configure output video properties\n","codec = cv2.VideoWriter_fourcc(*'mp4v')\n","frame_width = 0  # Set to 0 to use the same width as the input video\n","frame_height = 0  # Set to 0 to use the same height as the input video\n","fps = 30  # Set the desired output frame rate\n","\n","# Get input video properties\n","if frame_width == 0:\n","    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","if frame_height == 0:\n","    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Create video writer object\n","# out = cv2.VideoWriter(output_path, codec, fps, (frame_width, frame_height))\n","n_frames = 0\n","n_frames_wo_landmarks = 0\n","try:\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        n_frames += 1\n","        im = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=im)\n","        timestamp = cap.get(cv2.CAP_PROP_POS_MSEC)\n","        results = landmarker.detect_for_video(mp_image,mp.Timestamp.from_seconds(timestamp).microseconds())\n","        og_img = mp_image.numpy_view()\n","        og_img = cv2.cvtColor(og_img, cv2.COLOR_BGR2RGB)\n","        if len(results.face_landmarks) == 0:\n","    #         print(\"No landmarks detected\")\n","            annotated_image =  cv2.cvtColor(mp_image.numpy_view(), cv2.COLOR_BGR2RGB)\n","            # out.write(annotated_image)\n","            concatenated_image = np.concatenate((og_img, annotated_image), axis=1)\n","            # cv2.imshow('frame',concatenated_image)\n","            cv2.imshow('frame',annotated_image)\n","            \n","            n_frames_wo_landmarks += 1\n","            continue\n","    #     base_vector1 = np.array([1, 0, 0])\n","    #     base_vector2 = np.array([0, 1, 0])\n","    #     image_plane = np.cross(base_vector2, -base_vector1)\n","        image_plane = np.array([0, 0, 1])\n","\n","        ref = results.face_landmarks[0][440]\n","        result1 = results.face_landmarks[0][440]\n","        result2 = results.face_landmarks[0][363]\n","        result3 = results.face_landmarks[0][360]\n","        vec1 = [result1.x - result2.x, result1.y - result2.y, result1.z - result2.z]\n","        vec2 = [result2.x - result3.x, result2.y - result3.y, result2.z - result3.z]\n","        triangle_plane = np.cross(vec1, vec2)\n","        triangle_plane[0] = 0.\n","        triangle_plane = triangle_plane/np.linalg.norm(triangle_plane)\n","        triangle_plane_dot = np.dot(image_plane, triangle_plane)\n","        \n","        # hor1 = results.face_landmarks[0][220]\n","        # hor2 = results.face_landmarks[0][440]\n","        # ver1 = results.face_landmarks[0][3]\n","        # ver2 = results.face_landmarks[0][5]    \n","        # face_plane = np.cross([hor1.x - hor2.x, hor1.y - hor2.y, hor1.z - hor2.z], [ver1.x - ver2.x, ver1.y - ver2.y, ver1.z - ver2.z])\n","        # face_plane = face_plane/np.linalg.norm(face_plane)\n","        # face_plane_dot = np.dot(image_plane, face_plane)\n","        \n","        hor1 = results.face_landmarks[0][220]\n","        hor2 = results.face_landmarks[0][440]\n","        hor_ref = np.array([hor1.x - hor2.x, hor1.y - hor2.y, hor1.z - hor2.z])\n","        hor_ref = hor_ref/np.linalg.norm(hor_ref)\n","        face_hor_dot = np.dot(image_plane, hor_ref)\n","        \n","        occlusion_val = (face_hor_dot < -0.3) or (triangle_plane_dot < 0)\n","        # occlusion_val = (triangle_plane_dot < 0)\n","        # print(triangle_plane_dot)\n","        # occlusion_val = 0.1\n","        \n","        if not occlusion_val:\n","            coords = (mean([result1.x,result2.x,result3.x]), mean([result1.y,result2.y,result3.y]), mean([result1.z,result2.z,result3.z]))\n","            lmks = [[NormalizedLandmark(x=coords[0], y=coords[1], z=coords[2], visibility=0., presence=0.)]]\n","            annotated_image = draw_landmarks_on_image(mp_image.numpy_view(), lmks)\n","            # annotated_image = cv2.circle(mp_image.numpy_view(), coords, radius=2, color=(255,0,0), thickness=2)\n","        else:\n","            annotated_image = mp_image.numpy_view()\n","        annotated_image =  cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n","        # if ref.x < result1.x:\n","        # annotated_image = cv2.putText(img=annotated_image, text=f'{result1.visibility}', org=(50, 50), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.4, color=(255,0,0), thickness=1, lineType=cv2.LINE_AA)\n","        #     print(\"Occluded\")\n","        # out.write(annotated_image)\n","        concatenated_image = np.concatenate((og_img, annotated_image), axis=1)\n","\n","        # cv2.imshow('frame',concatenated_image)\n","        cv2.imshow('frame',annotated_image)\n","        \n","        # break\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","except Exception as e:\n","    raise e\n","finally:\n","    cap.release()   \n","    cv2.destroyAllWindows() \n","# out.release()\n","\n","\n","print(\"Total Frames:\", n_frames)\n","print(\"Frames Without Landmarks,\", n_frames_wo_landmarks)\n","print(\"Bad Frames\", n_frames_wo_landmarks/n_frames*100)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["res = np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.face_landmarks[0]])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["NormalizedLandmark(x=0.537566065788269, y=0.49689143896102905, z=-0.06263561546802521, visibility=0.0, presence=0.0)"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["ref"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["NormalizedLandmark(x=0.6659533977508545, y=0.5517739057540894, z=-0.01591748557984829, visibility=0.0, presence=0.0)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["result1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["NormalizedLandmark(x=0.542173445224762, y=0.6196877956390381, z=-0.041433509439229965, visibility=0.0, presence=0.0)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["results.face_landmarks[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T15:26:21.378372Z","iopub.status.busy":"2023-09-08T15:26:21.378014Z","iopub.status.idle":"2023-09-08T15:26:21.384225Z","shell.execute_reply":"2023-09-08T15:26:21.383007Z","shell.execute_reply.started":"2023-09-08T15:26:21.378343Z"},"trusted":true},"outputs":[],"source":["# 440 363 360\n","# 220 440 3 5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T15:26:21.387720Z","iopub.status.busy":"2023-09-08T15:26:21.386678Z","iopub.status.idle":"2023-09-08T15:26:21.400488Z","shell.execute_reply":"2023-09-08T15:26:21.399583Z","shell.execute_reply.started":"2023-09-08T15:26:21.387683Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([-1,  0,  0])"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["-np.array([1, 0, 0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T15:31:09.440820Z","iopub.status.busy":"2023-09-08T15:31:09.440482Z","iopub.status.idle":"2023-09-08T15:31:09.445635Z","shell.execute_reply":"2023-09-08T15:31:09.444442Z","shell.execute_reply.started":"2023-09-08T15:31:09.440791Z"},"trusted":true},"outputs":[],"source":["# results.face_landmarks"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.17"}},"nbformat":4,"nbformat_minor":4}
