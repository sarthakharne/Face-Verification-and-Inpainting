{"cells":[{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T19:19:21.885694Z","iopub.status.busy":"2023-09-13T19:19:21.884501Z","iopub.status.idle":"2023-09-13T19:19:21.890965Z","shell.execute_reply":"2023-09-13T19:19:21.889919Z","shell.execute_reply.started":"2023-09-13T19:19:21.885630Z"},"id":"8j0p-sIShO2D","trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","import os\n","import random\n","from itertools import combinations\n","from collections import defaultdict\n","from tqdm import tqdm\n","from PIL import Image\n","import copy\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torch.utils.data import WeightedRandomSampler\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.nn as nn"]},{"cell_type":"markdown","metadata":{},"source":["## Download and install our pre-trained model and its functions"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-13T19:19:21.893836Z","iopub.status.busy":"2023-09-13T19:19:21.893230Z","iopub.status.idle":"2023-09-13T19:19:36.234900Z","shell.execute_reply":"2023-09-13T19:19:36.233651Z","shell.execute_reply.started":"2023-09-13T19:19:21.893801Z"},"id":"ElN1hJp6fvqp","outputId":"5175096a-680c-428f-af91-c0527c2a2f6d","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting facenet-pytorch\n","  Downloading facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (1.23.5)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (2.31.0)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (0.15.1)\n","Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from facenet-pytorch) (9.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->facenet-pytorch) (2023.7.22)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision->facenet-pytorch) (2.0.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (3.12.2)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (4.6.3)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision->facenet-pytorch) (3.1.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision->facenet-pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision->facenet-pytorch) (1.3.0)\n","Installing collected packages: facenet-pytorch\n","Successfully installed facenet-pytorch-2.5.3\n"]}],"source":["!pip install facenet-pytorch\n","from facenet_pytorch import InceptionResnetV1"]},{"cell_type":"markdown","metadata":{},"source":["## Loading the dataset.\n","Please change the path."]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-13T19:19:36.238265Z","iopub.status.busy":"2023-09-13T19:19:36.237856Z","iopub.status.idle":"2023-09-13T19:19:41.204242Z","shell.execute_reply":"2023-09-13T19:19:41.203088Z","shell.execute_reply.started":"2023-09-13T19:19:36.238227Z"},"id":"3DKdQDkIhYNE","outputId":"50ca084e-f47c-4d09-c0c1-534977b0fc01","trusted":true},"outputs":[],"source":["faces = {}\n","dataset_path = '/kaggle/input/iiitb-faces/IIITB-FACES'\n","sub_folders = os.listdir(dataset_path)\n","for sub_folder in sub_folders:\n","    image_paths = os.listdir(os.path.join(dataset_path, sub_folder))\n","    for image_path in image_paths:\n","        image_path_actual = os.path.join(dataset_path, sub_folder, image_path)\n","        faces[image_path_actual] = cv2.resize(cv2.cvtColor(cv2.imread(image_path_actual), cv2.COLOR_BGR2GRAY), (400, 400))"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T19:19:41.215837Z","iopub.status.busy":"2023-09-13T19:19:41.215164Z","iopub.status.idle":"2023-09-13T19:19:41.822782Z","shell.execute_reply":"2023-09-13T19:19:41.821642Z","shell.execute_reply.started":"2023-09-13T19:19:41.215805Z"},"id":"h_18PBualOuQ","trusted":true},"outputs":[],"source":["dataset_dict = {}\n","for key in faces.keys():\n","    class_key = str(key.split('/')[5])\n","    if class_key in list(dataset_dict.keys()):\n","        dataset_dict[class_key] = dataset_dict[class_key] + [Image.open(key)]\n","    else:\n","        dataset_dict[class_key] = [Image.open(key)]"]},{"cell_type":"markdown","metadata":{},"source":["## Performing the train-test image split"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T19:19:41.824952Z","iopub.status.busy":"2023-09-13T19:19:41.824545Z","iopub.status.idle":"2023-09-13T19:19:45.769717Z","shell.execute_reply":"2023-09-13T19:19:45.768600Z","shell.execute_reply.started":"2023-09-13T19:19:41.824917Z"},"id":"Cy3kNo2rmhT1","trusted":true},"outputs":[],"source":["dataset_dict_test_split = {}\n","dataset_keys = list(dataset_dict.keys())\n","dataset_dict_test_split[str(dataset_keys[len(dataset_keys)-1])] = dataset_dict[str(dataset_keys[len(dataset_keys)-1])]\n","dataset_dict_new = {}\n","for i in range(len(dataset_keys)-1):\n","    dataset_dict_new[dataset_keys[i]] = dataset_dict[dataset_keys[i]]\n","dataset_dict_whole = copy.deepcopy(dataset_dict)\n","dataset_dict = copy.deepcopy(dataset_dict_new)\n","def split_dataset(dataset_dict, test_ratio=0.2):\n","    train_data = {}\n","    test_data = {}\n","\n","    for class_name, image_paths in dataset_dict.items():\n","        num_samples = len(image_paths)\n","        num_test_samples = int(test_ratio * num_samples)\n","        random.shuffle(image_paths)\n","        train_data[class_name] = image_paths[:-num_test_samples]\n","        test_data[class_name] = image_paths[-num_test_samples:]\n","\n","    return train_data, test_data\n","\n","train_data_dict, test_data_dict = split_dataset(dataset_dict)"]},{"cell_type":"markdown","metadata":{},"source":["## Writing our custom dataloaders"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T19:19:45.782047Z","iopub.status.busy":"2023-09-13T19:19:45.781290Z","iopub.status.idle":"2023-09-13T19:19:45.804162Z","shell.execute_reply":"2023-09-13T19:19:45.802954Z","shell.execute_reply.started":"2023-09-13T19:19:45.782009Z"},"id":"370ktVOqnbO9","trusted":true},"outputs":[],"source":["class SiameseDataset(Dataset):\n","    def __init__(self, data_dict, transform=None):\n","        self.data_dict = data_dict\n","        self.transform = transform\n","        self.class_pairs = []\n","        for class1 in self.data_dict.keys():\n","            for class2 in self.data_dict.keys():\n","                self.class_pairs.append([class1, class2])\n","        self.samples = self.generate_samples()\n","\n","\t#Used to generate pairs of data\n","    def generate_samples(self):\n","        samples = []\n","        for class1, class2 in self.class_pairs:\n","            for img1_path in self.data_dict[class1]:\n","                for img2_path in self.data_dict[class2]:\n","                    if class1 == class2:\n","                        label = 1\n","                    else:\n","                        label = 0\n","                    samples.append((img1_path, img2_path, label))\n","        return samples\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, index):\n","        img1_path, img2_path, label = self.samples[index]\n","\n","        img1 = img1_path\n","        img2 = img2_path\n","\n","        if self.transform is not None:\n","            img1 = self.transform(img1)\n","            img2 = self.transform(img2)\n","\n","        return img1, img2, label\n","\t\n","\t#This function is specifically made for weighted sampling. This will be used later\n","    def get_labels(self):\n","        labels = []\n","        for index in range(0, self.__len__()):\n","            labels.append(self.samples[index][2])\n","        return labels\n","\n","class SiameseDataset_Testing(Dataset):\n","    def __init__(self, data_dict_test, data_dict_whole, transform=None):\n","        self.data_dict_test = data_dict_test\n","        self.data_dict_whole = data_dict_whole\n","        self.transform = transform\n","        self.class_pairs = []\n","        for class1 in self.data_dict_test.keys():\n","            for class2 in self.data_dict_whole.keys():\n","                self.class_pairs.append([class1, class2])\n","        self.samples = self.generate_samples()\n","\n","\t#Used to generate pairs of data\n","    def generate_samples(self):\n","        samples = []\n","        for class1, class2 in self.class_pairs:\n","            for img1_path in self.data_dict_test[class1]:\n","                for img2_path in self.data_dict_whole[class2]:\n","                    if class1 == class2:\n","                        label = 1\n","                    else:\n","                        label = 0\n","                    samples.append((img1_path, img2_path, label))\n","        return samples\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, index):\n","        img1_path, img2_path, label = self.samples[index]\n","\n","        img1 = img1_path\n","        img2 = img2_path\n","\n","        if self.transform is not None:\n","            img1 = self.transform(img1)\n","            img2 = self.transform(img2)\n","\n","        return img1, img2, label\n","\n","\t#This function is specifically made for weighted sampling. This will be used later\n","    def get_labels(self):\n","        labels = []\n","        for index in range(0, self.__len__()):\n","            labels.append(self.samples[index][2])\n","        return labels"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-13T19:19:45.807951Z","iopub.status.busy":"2023-09-13T19:19:45.807512Z","iopub.status.idle":"2023-09-13T19:19:47.164092Z","shell.execute_reply":"2023-09-13T19:19:47.163054Z","shell.execute_reply.started":"2023-09-13T19:19:45.807919Z"},"id":"2tERhAWypkZm","outputId":"48a07ab5-a8cb-44b3-ab50-9842bdab19f2","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[452460, 9940]\n"]}],"source":["# Define transformations\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor()\n","])\n","\n","#Finding the weights/probabilites of the each sample in the train dataset, by using the frequency of the label.\n","train_dataset = SiameseDataset(train_data_dict, transform=transform)\n","class_counts = [0, 0]\n","for label in train_dataset.get_labels():\n","    class_counts[label] += 1\n","print(class_counts)\n","weights = [1.0 / class_counts[label] for label in train_dataset.get_labels()]\n","#Weighted Sampling for counteracting the label/class bias in the dataset\n","sampler = WeightedRandomSampler(\n","     weights=weights,\n","     num_samples=len(train_dataset),\n","     replacement=False\n",")\n","train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=128)\n","\n","test_dataset = SiameseDataset_Testing(test_data_dict, dataset_dict, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","\n","test_dataset_out_of_sample = SiameseDataset_Testing(dataset_dict_test_split, dataset_dict_whole, transform=transform)\n","test_loader_out_of_sample = DataLoader(test_dataset_out_of_sample, batch_size=128, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Defining our model architecture"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["c6a4480c7b0a46149f4b06966ea94ce6","98d85204b76e4a81979b41efa001e1a3","1c2dd1a0e2c44451b7f540e26f1de995","f641acd5c0324d47af882966b3e6b87d","475d4fcfd502477cb712e484ee507832","7de81ebaf45b4caf9e85009315728795","bb5a48c23afa4916920046fb68f3738c","fb650f09de2b4aec98a55eab11b741b1","0bd5b8f6de9644d6a5fee9e4f3455855","d409796c0ccc4644886a9630d1953d3b","1718f1be393c48cd83e886987c6d4208"]},"execution":{"iopub.execute_input":"2023-09-13T19:19:47.168822Z","iopub.status.busy":"2023-09-13T19:19:47.168481Z","iopub.status.idle":"2023-09-13T19:19:49.622615Z","shell.execute_reply":"2023-09-13T19:19:49.621634Z","shell.execute_reply.started":"2023-09-13T19:19:47.168791Z"},"id":"tWNcFvPbp5j0","outputId":"7ebdd5a4-af80-4bca-af04-2aa30ac5d0b9","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9cbaa0540cc5468893cddceba540cb31","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/107M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(device)\n","\n","DNN_facenet_model = InceptionResnetV1(pretrained='vggface2').eval()\n","class SiameseNetwork(nn.Module):\n","    def __init__(self):\n","        super(SiameseNetwork, self).__init__()\n","        self.conv_layers = DNN_facenet_model\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(512, 128), \n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.cosine_sim = nn.CosineSimilarity(dim=1, eps=1e-6)\n","\n","    def forward_one(self, x):\n","        x = self.conv_layers(x)\n","\t\t# Flatten\n","        x = x.view(x.size()[0], -1)  \n","        x = self.fc(x)\n","        return x\n","\n","    def forward(self, input1, input2):\n","        output1 = self.forward_one(input1)\n","        output2 = self.forward_one(input2)\n","\n","        similarity_score = self.cosine_sim(output1, output2)\n","        return similarity_score\n","\n","siamese_net = SiameseNetwork()\n","# print(siamese_net)"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"markdown","metadata":{},"source":["Also, during evaluation we find the un-normalised classification accuracy as well as the normalised classification accuracy.\n","Un-Normalised classification accuracy is nothing but classification accuracy, number(correct_predictions)/number(predictions)\n","Normalised classification accuracy is the average classification accuracy for every class:\n","\tNormalsied Classification accuracy = (number(correct_class1_predicitons)/number(class1) + number(correct_class2_predicitons)/number(class2))/2"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-13T19:19:49.626553Z","iopub.status.busy":"2023-09-13T19:19:49.626170Z","iopub.status.idle":"2023-09-13T20:13:53.863936Z","shell.execute_reply":"2023-09-13T20:13:53.862857Z","shell.execute_reply.started":"2023-09-13T19:19:49.626517Z"},"id":"Edr6xfiw4XA4","outputId":"42f4d9d5-24c3-4dbd-fd56-b1893766ddc0","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3613/3613 [42:44<00:00,  1.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Accuracy: 97.71%\n","Train Normalised Accuracy: 95.38%\n","Epoch [1/1] Loss: 2.2929\n","Test Accuracy: 97.72%\n","Test Normalised Accuracy: 95.44%\n","Out of Sample Test Accuracy: 96.41%\n","Out of Sample Test Normalised Accuracy: 98.17%\n"]}],"source":["criterion = nn.BCELoss()  \n","optimizer = optim.Adam(siamese_net.parameters(), lr=0.001)\n","\n","# Training loop\n","siamese_net.to(device)\n","num_epochs = 1\n","for epoch in range(num_epochs):\n","    siamese_net.train()\n","    total_loss = 0.0\n","    correct = 0\n","    correct_0 = 0\n","    correct_1 = 0\n","    total_0 = 0\n","    total_1 = 0\n","    total = 0\n","    for img1, img2, label in tqdm(train_loader):\n","        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n","        optimizer.zero_grad()\n","        output = siamese_net(img1, img2)\n","        predicted = (output > 0.75).float()\n","        correct += (predicted == label).sum().item()\n","        correct_0 += ((label.float() == 0.0) & (predicted == 0.0)).sum().item()\n","        correct_1 += ((label.float() == 1.0) & (predicted == 1.0)).sum().item()\n","        total_1 += (label.float() == 1.0).sum().item()\n","        total_0 += (label.float() == 0.0).sum().item()\n","        total += label.size(0)\n","        loss_similarity = criterion(predicted, label.float())\n","        loss = loss_similarity\n","        loss.requires_grad = True\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    accuracy = (correct / total) * 100.0\n","    print(f\"Train Accuracy: {accuracy:.2f}%\")\n","    norm_acc = (correct_0/total_0 + correct_1/total_1)/2 * 100\n","    print(f'Train Normalised Accuracy: {norm_acc:.2f}%')\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {total_loss / len(train_loader):.4f}\")\n","\n","    # Testing loop\n","    siamese_net.eval()\n","    correct = 0\n","    total = 0\n","    correct_0 = 0\n","    correct_1 = 0\n","    total_0 = 0\n","    total_1 = 0\n","    with torch.no_grad():\n","        for img1, img2, label in test_loader:\n","            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n","            output = siamese_net(img1, img2)\n","            predicted = (output > 0.75).float()\n","            correct += (predicted == label).sum().item()\n","            correct_0 += ((label.float() == 0.0) & (predicted == 0.0)).sum().item()\n","            correct_1 += ((label.float() == 1.0) & (predicted == 1.0)).sum().item()\n","            total_1 += (label.float() == 1.0).sum().item()\n","            total_0 += (label.float() == 0.0).sum().item()\n","            total += label.size(0)\n","        accuracy = (correct / total) * 100.0\n","        print(f\"Test Accuracy: {accuracy:.2f}%\")\n","        norm_acc = (correct_0/total_0 + correct_1/total_1)/2 * 100\n","        print(f'Test Normalised Accuracy: {norm_acc:.2f}%')\n","\n","        correct = 0\n","        correct_0 = 0\n","        correct_1 = 0\n","        total_0 = 0\n","        total_1 = 0\n","        total = 0\n","        for img1, img2, label in test_loader_out_of_sample:\n","            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n","            output = siamese_net(img1, img2)\n","            predicted = (output > 0.75).float()\n","            correct += (predicted == label).sum().item()\n","            correct_0 += ((label.float() == 0.0) & (predicted == 0.0)).sum().item()\n","            correct_1 += ((label.float() == 1.0) & (predicted == 1.0)).sum().item()\n","            total_1 += (label.float() == 1.0).sum().item()\n","            total_0 += (label.float() == 0.0).sum().item()\n","            total += label.size(0)\n","        accuracy = (correct / total) * 100.0\n","        print(f\"Out of Sample Test Accuracy: {accuracy:.2f}%\")\n","        norm_acc = (correct_0/total_0 + correct_1/total_1)/2 * 100\n","        print(f'Out of Sample Test Normalised Accuracy: {norm_acc:.2f}%')"]},{"cell_type":"markdown","metadata":{},"source":["## Saving the model"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T20:13:53.866006Z","iopub.status.busy":"2023-09-13T20:13:53.865649Z","iopub.status.idle":"2023-09-13T20:13:54.283724Z","shell.execute_reply":"2023-09-13T20:13:54.282286Z","shell.execute_reply.started":"2023-09-13T20:13:53.865973Z"},"id":"bZK2_-Un67GQ","trusted":true},"outputs":[],"source":["# Additional information\n","EPOCH = 1\n","PATH = \"model_ckpt.pt\"\n","\n","torch.save({\n","            'epoch': EPOCH,\n","            'model_state_dict': siamese_net.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            }, PATH)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0bd5b8f6de9644d6a5fee9e4f3455855":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1718f1be393c48cd83e886987c6d4208":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c2dd1a0e2c44451b7f540e26f1de995":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb650f09de2b4aec98a55eab11b741b1","max":111898327,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0bd5b8f6de9644d6a5fee9e4f3455855","value":111898327}},"475d4fcfd502477cb712e484ee507832":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de81ebaf45b4caf9e85009315728795":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98d85204b76e4a81979b41efa001e1a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7de81ebaf45b4caf9e85009315728795","placeholder":"​","style":"IPY_MODEL_bb5a48c23afa4916920046fb68f3738c","value":"100%"}},"bb5a48c23afa4916920046fb68f3738c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6a4480c7b0a46149f4b06966ea94ce6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98d85204b76e4a81979b41efa001e1a3","IPY_MODEL_1c2dd1a0e2c44451b7f540e26f1de995","IPY_MODEL_f641acd5c0324d47af882966b3e6b87d"],"layout":"IPY_MODEL_475d4fcfd502477cb712e484ee507832"}},"d409796c0ccc4644886a9630d1953d3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f641acd5c0324d47af882966b3e6b87d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d409796c0ccc4644886a9630d1953d3b","placeholder":"​","style":"IPY_MODEL_1718f1be393c48cd83e886987c6d4208","value":" 107M/107M [00:00&lt;00:00, 130MB/s]"}},"fb650f09de2b4aec98a55eab11b741b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":4}
