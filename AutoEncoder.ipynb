{"cells":[{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T18:12:07.603567Z","iopub.status.busy":"2023-09-13T18:12:07.603153Z","iopub.status.idle":"2023-09-13T18:12:07.609343Z","shell.execute_reply":"2023-09-13T18:12:07.608093Z","shell.execute_reply.started":"2023-09-13T18:12:07.603534Z"},"id":"8j0p-sIShO2D","trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","import os\n","import random\n","from PIL import Image\n","import copy\n","from tqdm import tqdm\n","from itertools import combinations\n","from collections import defaultdict\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torch.utils.data import WeightedRandomSampler\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import torch.nn.functional as F"]},{"cell_type":"markdown","metadata":{},"source":["## Loading the dataset.\n","Please change the path."]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-13T18:12:07.612900Z","iopub.status.busy":"2023-09-13T18:12:07.612393Z","iopub.status.idle":"2023-09-13T18:12:13.345697Z","shell.execute_reply":"2023-09-13T18:12:13.344504Z","shell.execute_reply.started":"2023-09-13T18:12:07.612861Z"},"id":"3DKdQDkIhYNE","outputId":"b03fc978-0373-499f-f480-1c78002dacd0","trusted":true},"outputs":[],"source":["faces = {}\n","dataset_path = '/kaggle/input/iiitb-faces/IIITB-FACES'\n","sub_folders = os.listdir(dataset_path)\n","for sub_folder in sub_folders:\n","    image_paths = os.listdir(os.path.join(dataset_path, sub_folder))\n","    for image_path in image_paths:\n","        image_path_actual = os.path.join(dataset_path, sub_folder, image_path)\n","        faces[image_path_actual] = cv2.resize(cv2.cvtColor(cv2.imread(image_path_actual), cv2.COLOR_BGR2GRAY), (400, 400))"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T18:12:13.360553Z","iopub.status.busy":"2023-09-13T18:12:13.359238Z","iopub.status.idle":"2023-09-13T18:12:13.955042Z","shell.execute_reply":"2023-09-13T18:12:13.953249Z","shell.execute_reply.started":"2023-09-13T18:12:13.360516Z"},"id":"h_18PBualOuQ","trusted":true},"outputs":[],"source":["dataset_dict = {}\n","for key in faces.keys():\n","    class_key = str(key.split('/')[5])\n","    if class_key in list(dataset_dict.keys()):\n","        dataset_dict[class_key] = dataset_dict[class_key] + [Image.open(key)]\n","    else:\n","        dataset_dict[class_key] = [Image.open(key)]"]},{"cell_type":"markdown","metadata":{},"source":["## Performing the train-test image split"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T18:12:13.969812Z","iopub.status.busy":"2023-09-13T18:12:13.965413Z","iopub.status.idle":"2023-09-13T18:12:17.172811Z","shell.execute_reply":"2023-09-13T18:12:17.171785Z","shell.execute_reply.started":"2023-09-13T18:12:13.969750Z"},"id":"Cy3kNo2rmhT1","trusted":true},"outputs":[],"source":["dataset_dict_test_split = {}\n","dataset_keys = list(dataset_dict.keys())\n","dataset_dict_test_split[str(dataset_keys[len(dataset_keys)-1])] = dataset_dict[str(dataset_keys[len(dataset_keys)-1])]\n","dataset_dict_new = {}\n","for i in range(len(dataset_keys)-1):\n","    dataset_dict_new[dataset_keys[i]] = dataset_dict[dataset_keys[i]]\n","dataset_dict_whole = copy.deepcopy(dataset_dict)\n","dataset_dict = copy.deepcopy(dataset_dict_new)\n","def split_dataset(dataset_dict, test_ratio=0.2):\n","    train_data = {}\n","    test_data = {}\n","\n","    for class_name, image_paths in dataset_dict.items():\n","        num_samples = len(image_paths)\n","        num_test_samples = int(test_ratio * num_samples)\n","        random.shuffle(image_paths)\n","        train_data[class_name] = image_paths[:-num_test_samples]\n","        test_data[class_name] = image_paths[-num_test_samples:]\n","\n","    return train_data, test_data\n","\n","train_data_dict, test_data_dict = split_dataset(dataset_dict)"]},{"cell_type":"markdown","metadata":{},"source":["## Writing our custom dataloaders"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T18:12:17.182711Z","iopub.status.busy":"2023-09-13T18:12:17.182368Z","iopub.status.idle":"2023-09-13T18:12:17.202554Z","shell.execute_reply":"2023-09-13T18:12:17.201488Z","shell.execute_reply.started":"2023-09-13T18:12:17.182679Z"},"id":"370ktVOqnbO9","trusted":true},"outputs":[],"source":["class SiameseDataset(Dataset):\n","    def __init__(self, data_dict, transform=None):\n","        self.data_dict = data_dict\n","        self.transform = transform\n","        self.class_pairs = []\n","        for class1 in self.data_dict.keys():\n","            for class2 in self.data_dict.keys():\n","                self.class_pairs.append([class1, class2])\n","        self.samples = self.generate_samples()\n","\n","\t#Used to generate pairs of data\n","    def generate_samples(self):\n","        samples = []\n","        for class1, class2 in self.class_pairs:\n","            for img1_path in self.data_dict[class1]:\n","                for img2_path in self.data_dict[class2]:\n","                    if class1 == class2:\n","                        label = 1\n","                    else:\n","                        label = 0\n","                    samples.append((img1_path, img2_path, label))\n","        return samples\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, index):\n","        img1_path, img2_path, label = self.samples[index]\n","\n","        img1 = img1_path\n","        img2 = img2_path\n","\n","        if self.transform is not None:\n","            img1 = self.transform(img1)\n","            img2 = self.transform(img2)\n","\n","        return img1, img2, label\n","    \n","\t#This function is specifically made for weighted sampling. This will be used later\n","    def get_labels(self):\n","        labels = []\n","        for index in range(0, self.__len__()):\n","            labels.append(self.samples[index][2])\n","        return labels\n","\n","class SiameseDataset_Testing(Dataset):\n","    def __init__(self, data_dict_test, data_dict_whole, transform=None):\n","        self.data_dict_test = data_dict_test\n","        self.data_dict_whole = data_dict_whole\n","        self.transform = transform\n","        self.class_pairs = []\n","        for class1 in self.data_dict_test.keys():\n","            for class2 in self.data_dict_whole.keys():\n","                self.class_pairs.append([class1, class2])\n","        self.samples = self.generate_samples()\n","\n","\t#Used to generate pairs of data\n","    def generate_samples(self):\n","        samples = []\n","        for class1, class2 in self.class_pairs:\n","            for img1_path in self.data_dict_test[class1]:\n","                for img2_path in self.data_dict_whole[class2]:\n","                    if class1 == class2:\n","                        label = 1\n","                    else:\n","                        label = 0\n","                    samples.append((img1_path, img2_path, label))\n","        return samples\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, index):\n","        img1_path, img2_path, label = self.samples[index]\n","\t\t\n","        img1 = img1_path\n","        img2 = img2_path\n","\n","        if self.transform is not None:\n","            img1 = self.transform(img1)\n","            img2 = self.transform(img2)\n","\n","        return img1, img2, label\n","    \n","\t#This function is specifically made for weighted sampling. This will be used later\n","    def get_labels(self):\n","        labels = []\n","        for index in range(0, self.__len__()):\n","            labels.append(self.samples[index][2])\n","        return labels"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T18:12:17.204492Z","iopub.status.busy":"2023-09-13T18:12:17.203902Z","iopub.status.idle":"2023-09-13T18:12:18.530101Z","shell.execute_reply":"2023-09-13T18:12:18.529046Z","shell.execute_reply.started":"2023-09-13T18:12:17.204460Z"},"id":"2tERhAWypkZm","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[452460, 9940]\n"]}],"source":["# Define transformations\n","transform = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor()\n","])\n","\n","#Finding the weights/probabilites of the each sample in the train dataset, by using the frequency of the label.\n","train_dataset = SiameseDataset(train_data_dict, transform=transform)\n","class_counts = [0, 0]\n","for label in train_dataset.get_labels():\n","    class_counts[label] += 1\n","print(class_counts)\n","weights = [1.0 / class_counts[label] for label in train_dataset.get_labels()]\n","#Weighted Sampling for counteracting the label/class bias in the dataset\n","sampler = WeightedRandomSampler(\n","     weights=weights,\n","     num_samples=len(train_dataset),\n","     replacement=True\n",")\n","train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=128)\n","\n","test_dataset = SiameseDataset_Testing(test_data_dict, dataset_dict, transform=transform)\n","test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","\n","test_dataset_out_of_sample = SiameseDataset_Testing(dataset_dict_test_split, dataset_dict_whole, transform=transform)\n","test_loader_out_of_sample = DataLoader(test_dataset_out_of_sample, batch_size=128, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Defining our model architecture"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-13T18:12:18.536497Z","iopub.status.busy":"2023-09-13T18:12:18.536170Z","iopub.status.idle":"2023-09-13T18:12:18.706699Z","shell.execute_reply":"2023-09-13T18:12:18.705776Z","shell.execute_reply.started":"2023-09-13T18:12:18.536469Z"},"id":"tWNcFvPbp5j0","outputId":"52d9680e-4525-469b-f504-a2d1ff5e6a5c","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["SiameseNetwork(\n","  (conv_layers): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (9): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n","    (10): ReLU(inplace=True)\n","  )\n","  (decode): Sequential(\n","    (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(2, 2))\n","    (5): ReLU(inplace=True)\n","    (6): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2))\n","    (7): Sigmoid()\n","  )\n","  (fc): Sequential(\n","    (0): Linear(in_features=43264, out_features=512, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Linear(in_features=512, out_features=256, bias=True)\n","    (3): ReLU(inplace=True)\n","    (4): Linear(in_features=256, out_features=128, bias=True)\n","    (5): ReLU(inplace=True)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=2, out_features=1, bias=True)\n","    (1): Sigmoid()\n","  )\n","  (cosine_sim): CosineSimilarity()\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")\n"]}],"source":["class SiameseNetwork(nn.Module):\n","    def __init__(self):\n","        super(SiameseNetwork, self).__init__()\n","\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=5),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2,2),\n","            nn.Conv2d(32, 64, kernel_size=5),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2,2),\n","            nn.Conv2d(64, 128, kernel_size=2),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(2,2),\n","            nn.Conv2d(128, 256, kernel_size=2),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.decode = nn.Sequential(\n","            nn.ConvTranspose2d(256, 128,\n","                               kernel_size=3, stride=2),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(128, 64,\n","                               kernel_size=4, stride=1),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(64, 32,\n","                               kernel_size=5, stride=2),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(32, 3,\n","                               kernel_size=4, stride=2),\n","            nn.Sigmoid()\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(43264, 512),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(512, 256),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(256, 128),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        self.dropout = nn.Dropout(p=0.2)\n","\n","    def forward_one(self, x):\n","        x = self.conv_layers(x)\n","        decoded_x = self.decode(x)\n","        # Flatten\n","        x = x.view(x.size()[0], -1)  \n","        x = self.fc(x)\n","        return x, decoded_x\n","\n","    def forward(self, input1, input2):\n","        output1, decoded1 = self.forward_one(input1)\n","        output2, decoded2 = self.forward_one(input2)\n","\n","        return output1, output2, decoded1, decoded2\n","\n","siamese_net = SiameseNetwork()\n","print(siamese_net)"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"markdown","metadata":{},"source":["Also, during evaluation we find the un-normalised classification accuracy as well as the normalised classification accuracy.\n","Un-Normalised classification accuracy is nothing but classification accuracy, number(correct_predictions)/number(predictions)\n","Normalised classification accuracy is the average classification accuracy for every class:\n","\tNormalsied Classification accuracy = (number(correct_class1_predicitons)/number(class1) + number(correct_class2_predicitons)/number(class2))/2"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-09-13T18:12:18.709422Z","iopub.status.busy":"2023-09-13T18:12:18.708684Z","iopub.status.idle":"2023-09-13T19:10:00.793331Z","shell.execute_reply":"2023-09-13T19:10:00.792226Z","shell.execute_reply.started":"2023-09-13T18:12:18.709370Z"},"id":"Edr6xfiw4XA4","outputId":"407f3afe-fb27-4b43-f202-0945d45f6c93","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 3.4876770769187715e-06: 100%|██████████| 3613/3613 [47:40<00:00,  1.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1] Loss: 0.0004\n","Test Accuracy: 97.32%\n","Test Normalised Accuracy: 98.30%\n","Out of sample Test Accuracy out of sample: 90.38%\n","Out of sample Test Normalised Accuracy: 95.09%\n"]}],"source":["class ContrastiveLoss(torch.nn.Module):\n","    def __init__(self, margin=0.2):\n","        super(ContrastiveLoss, self).__init__()\n","        self.margin = margin\n","\n","    def forward(self, output1, output2, label):\n","        euclidean_distance = F.pairwise_distance(output1, output2)\n","        loss_contrastive = torch.mean((label) * torch.pow(euclidean_distance, 2) +\n","                                      (1-label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n","        return loss_contrastive\n","\n","criterion = ContrastiveLoss()\n","criterion_reconstruction = nn.MSELoss()\n","optimizer = optim.Adam(siamese_net.parameters(), lr=0.00001)\n","\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(device)\n","\n","# Training loop\n","siamese_net.to(device)\n","num_epochs = 1\n","for epoch in range(num_epochs):\n","    siamese_net.train()\n","    total_loss = 0.0\n","    \n","    progress_bar = tqdm(train_loader)\n","    for img1, img2, label in progress_bar:\n","        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n","        optimizer.zero_grad()\n","        output1, output2, decoded1, decoded2 = siamese_net(img1, img2)\n","        loss_contrastive = criterion(output1, output2, label.float())\n","        loss_reconstruction = 0.00001*criterion_reconstruction(img1, decoded1) + 0.00001*criterion_reconstruction(img2, decoded2)\n","        loss = loss_contrastive + loss_reconstruction\n","        loss.backward()\n","        optimizer.step()\n","        progress_bar.set_description(f'Loss: {loss.item()}')\n","        total_loss += loss.item()\n","    \n","    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {total_loss / len(train_loader):.4f}\")\n","\n","    # Testing loop\n","    siamese_net.eval()\n","    correct = 0\n","    total = 0\n","    correct_0 = 0\n","    correct_1 = 0\n","    total_0 = 0\n","    total_1 = 0\n","    with torch.no_grad():\n","        for img1, img2, label in test_loader:\n","            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n","            output1, output2, decoded1, decoded2 = siamese_net(img1, img2)\n","            predicted = (F.pairwise_distance(output1, output2) <= 0.2).float()\n","            correct += (predicted == label).sum().item()\n","            correct_0 += ((label.float() == 0.0) & (predicted == 0.0)).sum().item()\n","            correct_1 += ((label.float() == 1.0) & (predicted == 1.0)).sum().item()\n","            total_1 += (label.float() == 1.0).sum().item()\n","            total_0 += (label.float() == 0.0).sum().item()\n","            total += label.size(0)\n","\n","        accuracy = (correct / total) * 100.0\n","        print(f\"Test Accuracy: {accuracy:.2f}%\")\n","        norm_acc = (correct_0/total_0 + correct_1/total_1)/2 * 100\n","        print(f'Test Normalised Accuracy: {norm_acc:.2f}%')\n","\n","        correct = 0\n","        total = 0\n","        correct_0 = 0\n","        correct_1 = 0\n","        total_0 = 0\n","        total_1 = 0\n","        for img1, img2, label in test_loader_out_of_sample:\n","            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n","            output1, output2, decoded1, decoded2 = siamese_net(img1, img2)\n","            predicted = (F.pairwise_distance(output1, output2) <= 0.2).float()\n","            correct += (predicted == label).sum().item()\n","            correct_0 += ((label.float() == 0.0) & (predicted == 0.0)).sum().item()\n","            correct_1 += ((label.float() == 1.0) & (predicted == 1.0)).sum().item()\n","            total_1 += (label.float() == 1.0).sum().item()\n","            total_0 += (label.float() == 0.0).sum().item()\n","            total += label.size(0)\n","        accuracy = (correct / total) * 100.0\n","        print(f\"Out of sample Test Accuracy out of sample: {accuracy:.2f}%\")\n","        norm_acc = (correct_0/total_0 + correct_1/total_1)/2 * 100\n","        print(f'Out of sample Test Normalised Accuracy: {norm_acc:.2f}%')"]},{"cell_type":"markdown","metadata":{},"source":["## Saving the model"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-09-13T19:10:00.795377Z","iopub.status.busy":"2023-09-13T19:10:00.795017Z","iopub.status.idle":"2023-09-13T19:10:01.179826Z","shell.execute_reply":"2023-09-13T19:10:01.178846Z","shell.execute_reply.started":"2023-09-13T19:10:00.795341Z"},"trusted":true},"outputs":[],"source":["EPOCH = 1\n","PATH = \"model_ckpt.pt\"\n","\n","torch.save({\n","            'epoch': EPOCH,\n","            'model_state_dict': siamese_net.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            }, PATH)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
