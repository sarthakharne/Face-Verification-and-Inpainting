{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mediapipe ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-10T05:36:39.176137Z","iopub.execute_input":"2023-09-10T05:36:39.176616Z","iopub.status.idle":"2023-09-10T05:36:57.930723Z","shell.execute_reply.started":"2023-09-10T05:36:39.176580Z","shell.execute_reply":"2023-09-10T05:36:57.929507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/latest/face_landmarker.task","metadata":{"execution":{"iopub.status.busy":"2023-09-10T05:36:57.934314Z","iopub.execute_input":"2023-09-10T05:36:57.934841Z","iopub.status.idle":"2023-09-10T05:36:59.297113Z","shell.execute_reply.started":"2023-09-10T05:36:57.934771Z","shell.execute_reply":"2023-09-10T05:36:59.295603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/working/face_landmarker.task'","metadata":{"execution":{"iopub.status.busy":"2023-09-10T05:36:59.298894Z","iopub.execute_input":"2023-09-10T05:36:59.299264Z","iopub.status.idle":"2023-09-10T05:36:59.305755Z","shell.execute_reply.started":"2023-09-10T05:36:59.299229Z","shell.execute_reply":"2023-09-10T05:36:59.304243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import mediapipe as mp\nfrom mediapipe import solutions\nfrom mediapipe.framework.formats import landmark_pb2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom google.protobuf import timestamp_pb2\nfrom statistics import mean","metadata":{"execution":{"iopub.status.busy":"2023-09-10T05:36:59.307549Z","iopub.execute_input":"2023-09-10T05:36:59.307933Z","iopub.status.idle":"2023-09-10T05:37:09.650170Z","shell.execute_reply.started":"2023-09-10T05:36:59.307903Z","shell.execute_reply":"2023-09-10T05:37:09.648814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_path = '/kaggle/input/trialvideo/sample.mp4'\nimage_path = '/kaggle/input/trialvideo/ring-xs.png'\noutput_path = 'output_video.mp4'","metadata":{"execution":{"iopub.status.busy":"2023-09-10T05:37:09.654112Z","iopub.execute_input":"2023-09-10T05:37:09.655112Z","iopub.status.idle":"2023-09-10T05:37:09.660786Z","shell.execute_reply.started":"2023-09-10T05:37:09.655066Z","shell.execute_reply":"2023-09-10T05:37:09.659840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def draw_landmarks_on_image(rgb_image, detection_result):\n  face_landmarks_list = detection_result.face_landmarks\n  annotated_image = np.copy(rgb_image)\n\n  # Loop through the detected faces to visualize.\n  for idx in range(len(face_landmarks_list)):\n    face_landmarks = face_landmarks_list[idx]\n\n    # Draw the face landmarks.\n    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n    face_landmarks_proto.landmark.extend([\n      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n    ])\n\n    solutions.drawing_utils.draw_landmarks(\n        image=annotated_image,\n        landmark_list=face_landmarks_proto,\n        connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n        landmark_drawing_spec=None,\n        connection_drawing_spec=mp.solutions.drawing_styles\n        .get_default_face_mesh_tesselation_style())\n    solutions.drawing_utils.draw_landmarks(\n        image=annotated_image,\n        landmark_list=face_landmarks_proto,\n        connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n        landmark_drawing_spec=None,\n        connection_drawing_spec=mp.solutions.drawing_styles\n        .get_default_face_mesh_contours_style())\n    solutions.drawing_utils.draw_landmarks(\n        image=annotated_image,\n        landmark_list=face_landmarks_proto,\n        connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n          landmark_drawing_spec=None,\n          connection_drawing_spec=mp.solutions.drawing_styles\n          .get_default_face_mesh_iris_connections_style())\n\n  return annotated_image","metadata":{"execution":{"iopub.status.busy":"2023-09-10T05:37:09.662524Z","iopub.execute_input":"2023-09-10T05:37:09.663458Z","iopub.status.idle":"2023-09-10T05:37:09.691522Z","shell.execute_reply.started":"2023-09-10T05:37:09.663419Z","shell.execute_reply":"2023-09-10T05:37:09.689925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BaseOptions = mp.tasks.BaseOptions\nFaceLandmarker = mp.tasks.vision.FaceLandmarker\nFaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\nFaceLandmarkerResult = mp.tasks.vision.FaceLandmarkerResult\nVisionRunningMode = mp.tasks.vision.RunningMode\n\noptions = FaceLandmarkerOptions(\n    base_options=BaseOptions(model_asset_path=model_path),\n    running_mode=VisionRunningMode.VIDEO)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T05:51:47.301911Z","iopub.execute_input":"2023-09-10T05:51:47.302515Z","iopub.status.idle":"2023-09-10T05:51:47.347335Z","shell.execute_reply.started":"2023-09-10T05:51:47.302472Z","shell.execute_reply":"2023-09-10T05:51:47.345419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a face landmarker instance with the live stream mode:\ndef print_result(result: FaceLandmarkerResult, output_image: mp.Image, timestamp_ms: int):\n    print('face landmarker result: {}'.format(result))","metadata":{"execution":{"iopub.status.busy":"2023-09-10T05:51:48.439685Z","iopub.execute_input":"2023-09-10T05:51:48.440195Z","iopub.status.idle":"2023-09-10T05:51:48.446848Z","shell.execute_reply.started":"2023-09-10T05:51:48.440160Z","shell.execute_reply":"2023-09-10T05:51:48.445137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_overlay(frame,img,x,y):\n    ''' Creates the overlay for the given frame and return the frame for overlay which will be\n        weighted added to the original frame\n    '''\n    h,w,_ = frame.shape\n    overlay = np.zeros((h,w,3),dtype='uint8')\n    \n    img_h,img_w,_ = img.shape\n    try:\n        for i in range(0,img_h):\n            for j in range(0,img_w):\n                if(img[i,j][0]!=0 or img[i,j][1]!=0 or img[i,j][2]!=0 ):\n                    overlay[x+i,y+j] = img[i,j]\n    except IndexError:\n        pass\n    return overlay ","metadata":{"execution":{"iopub.status.busy":"2023-09-10T06:04:30.582931Z","iopub.execute_input":"2023-09-10T06:04:30.583432Z","iopub.status.idle":"2023-09-10T06:04:30.593627Z","shell.execute_reply.started":"2023-09-10T06:04:30.583395Z","shell.execute_reply":"2023-09-10T06:04:30.592043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode='img'","metadata":{"execution":{"iopub.status.busy":"2023-09-10T06:04:31.812133Z","iopub.execute_input":"2023-09-10T06:04:31.812550Z","iopub.status.idle":"2023-09-10T06:04:31.818425Z","shell.execute_reply.started":"2023-09-10T06:04:31.812519Z","shell.execute_reply":"2023-09-10T06:04:31.816936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"landmarker = FaceLandmarker.create_from_options(options)\n\ncap = cv2.VideoCapture(video_path)\nring_image = cv2.imread(image_path)\nring_image = cv2.resize(ring_image, (32,32))\n\n# Configure output video properties\ncodec = cv2.VideoWriter_fourcc(*'mp4v')\nframe_width = 0  # Set to 0 to use the same width as the input video\nframe_height = 0  # Set to 0 to use the same height as the input video\nfps = 30  # Set the desired output frame rate\n\n# Check if video was successfully opened\nif not cap.isOpened():\n    print(\"Failed to open the video file.\")\n    exit()\n\n# Get input video properties\nif frame_width == 0:\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nif frame_height == 0:\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n# Create video writer object\nout = cv2.VideoWriter(output_path, codec, fps, (frame_width, frame_height))\n\n# Configure output video properties\ncodec = cv2.VideoWriter_fourcc(*'mp4v')\nframe_width = 0  # Set to 0 to use the same width as the input video\nframe_height = 0  # Set to 0 to use the same height as the input video\nfps = 30  # Set the desired output frame rate\n\n# Get input video properties\nif frame_width == 0:\n    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nif frame_height == 0:\n    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n# Create video writer object\nout = cv2.VideoWriter(output_path, codec, fps, (frame_width, frame_height))\nn_frames = 0\nn_frames_wo_landmarks = 0\n\nwhile True:\n    ret, frame = cap.read()\n    if not ret:\n        break\n    n_frames += 1\n    im = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=im)\n    timestamp = cap.get(cv2.CAP_PROP_POS_MSEC)\n    results = landmarker.detect_for_video(mp_image,mp.Timestamp.from_seconds(timestamp).microseconds())\n    if len(results.face_landmarks) == 0:\n        annotated_image = mp_image.numpy_view()\n        annotated_image =  cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n        out.write(annotated_image)\n        n_frames_wo_landmarks += 1\n        continue\n#     annotated_image = draw_landmarks_on_image(mp_image.numpy_view(), results)\n#     base_vector1 = np.array([1, 0, 0])\n#     base_vector2 = np.array([0, 1, 0])\n#     image_plane = np.cross(base_vector2, -base_vector1)\n    image_plane = np.array([0, 0, 1])\n    result1 = results.face_landmarks[0][440]\n    result2 = results.face_landmarks[0][363]\n    result3 = results.face_landmarks[0][360]\n    vec1 = [result1.x - result2.x, result1.y - result2.y, result1.z - result2.z]\n    vec2 = [result2.x - result3.x, result2.y - result3.y, result2.z - result3.z]\n    triangle_plane = np.cross(vec1, vec2)\n    \n    occlusion_val = np.dot(image_plane, triangle_plane)\n    \n    if occlusion_val > 0:\n        coords = (int(frame_width*mean([result1.x,result2.x,result3.x])), int(frame_height*mean([result1.y,result2.y,result3.y])))\n        if mode=='img':\n            overlay = build_overlay(mp_image.numpy_view(),ring_image,coords[1],coords[0])\n            annotated_image = cv2.addWeighted(overlay,1,mp_image.numpy_view(),1,0.0)\n        else: \n            annotated_image = cv2.circle(mp_image.numpy_view(), coords, radius=2, color=(255,0,0), thickness=2)\n    else:\n        annotated_image = mp_image.numpy_view()\n    annotated_image =  cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n    out.write(annotated_image)\ncap.release()\nout.release()\n\nprint(\"Total Frames:\", n_frames)\nprint(\"Frames Without Landmarks,\", n_frames_wo_landmarks)\nprint(\"Bad Frames\", n_frames_wo_landmarks/n_frames*100)","metadata":{"execution":{"iopub.status.busy":"2023-09-10T06:06:33.834294Z","iopub.execute_input":"2023-09-10T06:06:33.834769Z","iopub.status.idle":"2023-09-10T06:06:51.846447Z","shell.execute_reply.started":"2023-09-10T06:06:33.834734Z","shell.execute_reply":"2023-09-10T06:06:51.845288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}